{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "#from skimage import io\n",
    "#from skimage.util import img_as_float, img_as_ubyte\n",
    "#import matplotlib.cm as cm\n",
    "#from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "import time\n",
    "from six.moves import xrange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../Data/mean_normalised_df_no_class_bias.pkl') \n",
    "mean_img = pd.read_pickle('../Data/mean_img_no_class_bias.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATCH_DIM = 31\n",
    "BATCH_SIZE = 60\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(size, df, current_batch_ind):\n",
    "    \"\"\"Returns the next mini batch of data from the dataset passed\n",
    "    \n",
    "    Args:\n",
    "        size: length of the current requested mini batch\n",
    "        df: the data set consisting of the images and the labels\n",
    "        current_batch_ind: the current position of the index in the dataset\n",
    "    \n",
    "    Returns:\n",
    "        (batch_x, batch_y): A tuple of np arrays of dimensions \n",
    "                        [size, patch_dim**2*3] and [size, NUM_CLASSES] respectively \n",
    "        current_batch_ind: the updated current position of the index in the dataset\n",
    "        df: when the requested batch_size+current_batch_ind is more than the length of the data set,\n",
    "            the data is shuffled again and current_batch_ind is reset to 0, and this new data set is\n",
    "            returned\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if current_batch_ind + size> len(df):\n",
    "        current_batch_ind = 0\n",
    "        df = df.iloc[np.random.permutation(len(df))]\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "    batch_x = np.zeros((size, PATCH_DIM**2*3))\n",
    "    batch_y = np.zeros((size, NUM_CLASSES), dtype = 'uint8')\n",
    "    for i in range(current_batch_ind, current_batch_ind+size):\n",
    "        batch_x[i - current_batch_ind] = df.loc[i][:-1]\n",
    "        batch_y[i - current_batch_ind][int(df.loc[i][PATCH_DIM**2*3])]=1\n",
    "        \n",
    "    current_batch_ind += size  \n",
    "    return (batch_x, batch_y), current_batch_ind, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images, keep_prob, fc_hidden_units1=512):\n",
    "    \"\"\" Builds the model as far as is required for running the network\n",
    "    forward to make predictions.\n",
    "\n",
    "    Args:\n",
    "        images: Images placeholder, from inputs().\n",
    "        keep_prob: Probability used for Droupout in the final Affine Layer\n",
    "        fc_hidden_units1: Number of hidden neurons in final Affine layer\n",
    "    Returns:\n",
    "        softmax_linear: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('h_conv1') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[4, 4, 3, 64], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.05))\n",
    "        \n",
    "        # Flattening the 3D image into a 1D array\n",
    "        x_image = tf.reshape(images, [-1,PATCH_DIM,PATCH_DIM,3])\n",
    "        z = tf.nn.conv2d(x_image, weights, strides=[1, 1, 1, 1], padding='VALID')\n",
    "        h_conv1 = tf.nn.relu(z+biases, name=scope.name)\n",
    "    with tf.variable_scope('h_conv2') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[4, 4, 64, 64], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.05))\n",
    "        z = tf.nn.conv2d(h_conv1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv2 = tf.nn.relu(z+biases, name=scope.name)\n",
    "    \n",
    "    h_pool1 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name='h_pool1')\n",
    "    \n",
    "    with tf.variable_scope('h_conv3') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[4, 4, 64, 64], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.05))\n",
    "        z = tf.nn.conv2d(h_pool1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv3 = tf.nn.relu(z+biases, name=scope.name)\n",
    "        \n",
    "    h_pool2 = tf.nn.max_pool(h_conv3, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name='h_pool2')\n",
    "    \n",
    "    with tf.variable_scope('h_fc1') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[7**2*64, fc_hidden_units1], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable('biases', shape=[fc_hidden_units1], initializer=tf.constant_initializer(0.05))\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        \n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, weights) + biases, name = 'h_fc1')\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "        \n",
    "        \n",
    "    with tf.variable_scope('h_fc2') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[fc_hidden_units1, NUM_CLASSES], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable('biases', shape=[NUM_CLASSES])\n",
    "        \n",
    "        logits = (tf.matmul(h_fc1_drop, weights) + biases)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(logits, labels):\n",
    "    \"\"\"Calculates the loss from the logits and the labels.\n",
    "    Args:\n",
    "        logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "        labels: Labels tensor, int32 - [batch_size].\n",
    "    Returns:\n",
    "        loss: Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    labels = tf.to_float(labels)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, labels, name='xentropy')\n",
    "    loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def placeholder_inputs(batch_size):\n",
    "    \"\"\"Generate placeholder variables to represent the input tensors.\n",
    "    \n",
    "    These placeholders are used as inputs by the rest of the model building\n",
    "    code and will be fed from the downloaded data in the .run() loop, below.\n",
    "    Args:\n",
    "        batch_size: The batch size will be baked into both placeholders.\n",
    "    Returns:\n",
    "        images_placeholder: Images placeholder.\n",
    "        labels_placeholder: Labels placeholder.\n",
    "    \"\"\"\n",
    "    # Note that the shapes of the placeholders match the shapes of the full\n",
    "    # image and label tensors, except the first dimension is now batch_size\n",
    "    # rather than the full size of the train or test data sets.\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(batch_size, PATCH_DIM**2*3))\n",
    "    labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size, NUM_CLASSES))\n",
    "    return images_placeholder, labels_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#UPDATE current_img_ind\n",
    "def fill_feed_dict(data_set, images_pl, labels_pl, current_img_ind, batch_size):\n",
    "    \"\"\"Fills the feed_dict for training the given step.\n",
    "    A feed_dict takes the form of:\n",
    "    feed_dict = {\n",
    "                  <placeholder>: <tensor of values to be passed for placeholder>,\n",
    "                  ....\n",
    "                }\n",
    "    Args:\n",
    "        data_set: The set of images and labels, from input_data.read_data_sets()\n",
    "        images_pl: The images placeholder, from placeholder_inputs().\n",
    "        labels_pl: The labels placeholder, from placeholder_inputs().\n",
    "        current_img_ind: The current position of the index in the dataset\n",
    "    Returns:\n",
    "        feed_dict: The feed dictionary mapping from placeholders to values.\n",
    "        current_img_ind: The updated position of the index in the dataset\n",
    "        data_set: updated data_set\n",
    "    \"\"\"\n",
    "    # Create the feed_dict for the placeholders filled with the next\n",
    "    # `batch size ` examples.\n",
    "    batch, current_img_ind, data_set= next_batch(batch_size, data_set, current_img_ind)\n",
    "\n",
    "    feed_dict = {\n",
    "      images_pl: batch[0],\n",
    "      labels_pl: batch[1],\n",
    "    }\n",
    "    return feed_dict, current_img_ind, data_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 2)\n",
      "0.0704492\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    # Generate placeholders for the images and labels.\n",
    "    images_placeholder, labels_placeholder = placeholder_inputs(BATCH_SIZE)\n",
    "\n",
    "    # Build a Graph that computes predictions from the inference model.\n",
    "    logits = inference(images_placeholder, 0.5, 512)\n",
    "    loss = calc_loss(logits, labels_placeholder)\n",
    "\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Create a session for running Ops on the Graph.\n",
    "    with tf.Session() as sess:\n",
    "        current_img_ind = 0\n",
    "        start_time = time.time()\n",
    "        saver.restore(sess, '../Data/model.ckpt')\n",
    "        \n",
    "        # Fill a feed dictionary with the actual set of images and labels\n",
    "        # for this particular training step.\n",
    "        feed_dict, current_img_ind, data = fill_feed_dict(data,\n",
    "                                 images_placeholder,\n",
    "                                 labels_placeholder, current_img_ind=current_img_ind, \n",
    "                                                        batch_size=BATCH_SIZE)\n",
    "\n",
    "        predictions, loss_value = sess.run([logits, loss],\n",
    "                               feed_dict=feed_dict)\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        print predictions.shape\n",
    "        \n",
    "        print loss_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
