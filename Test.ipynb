{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from skimage import io, color, measure\n",
    "from skimage.util import img_as_float, img_as_ubyte\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import time\n",
    "from six.moves import xrange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_img = pd.read_pickle('../Data/mean_img_no_class_bias.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATCH_DIM = 31\n",
    "BATCH_SIZE = 100 # Must be a perfect square\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_path(directory):\n",
    "    imgs = glob.glob(directory + '/images/*.tif')\n",
    "    imgs.sort()\n",
    "    #a = [x.split('/')[-1].split('.')[0] for x in train]\n",
    "    \n",
    "    mask = glob.glob(directory + '/mask/*.gif')\n",
    "    mask.sort()\n",
    "    #b = [x.split('/')[-1].split('.')[0] for x in mask]\n",
    "    \n",
    "    gt = glob.glob(directory + '/1st_manual/*.gif')\n",
    "    gt.sort()\n",
    "    #c = [x.split('/')[-1].split('.')[0] for x in gt]\n",
    "    \n",
    "    return map(os.path.abspath, imgs), map(os.path.abspath, mask), map(os.path.abspath, gt)\n",
    "\n",
    "train, mask_train, gt_train =  get_path('../Data/DRIVE/training')\n",
    "test, mask_test, gt_test = get_path('../Data/DRIVE/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images, keep_prob, fc_hidden_units1=512):\n",
    "    \"\"\" Builds the model as far as is required for running the network\n",
    "    forward to make predictions.\n",
    "\n",
    "    Args:\n",
    "        images: Images placeholder, from inputs().\n",
    "        keep_prob: Probability used for Droupout in the final Affine Layer\n",
    "        fc_hidden_units1: Number of hidden neurons in final Affine layer\n",
    "    Returns:\n",
    "        softmax_linear: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('h_conv1') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[4, 4, 3, 64], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.05))\n",
    "        \n",
    "        # Flattening the 3D image into a 1D array\n",
    "        x_image = tf.reshape(images, [-1,PATCH_DIM,PATCH_DIM,3])\n",
    "        z = tf.nn.conv2d(x_image, weights, strides=[1, 1, 1, 1], padding='VALID')\n",
    "        h_conv1 = tf.nn.relu(z+biases, name=scope.name)\n",
    "    with tf.variable_scope('h_conv2') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[4, 4, 64, 64], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.05))\n",
    "        z = tf.nn.conv2d(h_conv1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv2 = tf.nn.relu(z+biases, name=scope.name)\n",
    "    \n",
    "    h_pool1 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name='h_pool1')\n",
    "    \n",
    "    with tf.variable_scope('h_conv3') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[4, 4, 64, 64], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.05))\n",
    "        z = tf.nn.conv2d(h_pool1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv3 = tf.nn.relu(z+biases, name=scope.name)\n",
    "        \n",
    "    h_pool2 = tf.nn.max_pool(h_conv3, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name='h_pool2')\n",
    "    \n",
    "    with tf.variable_scope('h_fc1') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[7**2*64, fc_hidden_units1], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable('biases', shape=[fc_hidden_units1], initializer=tf.constant_initializer(0.05))\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        \n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, weights) + biases, name = 'h_fc1')\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "        \n",
    "        \n",
    "    with tf.variable_scope('h_fc2') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[fc_hidden_units1, NUM_CLASSES], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable('biases', shape=[NUM_CLASSES])\n",
    "        \n",
    "        logits = (tf.matmul(h_fc1_drop, weights) + biases)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def placeholder_inputs(batch_size):\n",
    "    \"\"\"Generate placeholder variables to represent the input tensors.\n",
    "    Args:\n",
    "        batch_size: The batch size will be baked into both placeholders.\n",
    "    Returns:\n",
    "        images_placeholder: Images placeholder.\n",
    "    \"\"\"\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(batch_size, PATCH_DIM**2*3))\n",
    "    return images_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    \"\"\" Performs softmax operation on logits\n",
    "    \n",
    "        Args:\n",
    "            logits: logits from inference module\n",
    "        Output:\n",
    "            Softmax of logits    \n",
    "    \"\"\"\n",
    "    return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "segmented = np.zeros(image.shape[:2])\n",
    "\n",
    "rows = np.zeros(BATCH_SIZE, dtype='uint8')\n",
    "cols = np.zeros(BATCH_SIZE, dtype='uint8')\n",
    "feed = np.zeros((BATCH_SIZE, PATCH_DIM**2*3))\n",
    "predictions = np.zeros(BATCH_SIZE)\n",
    "\n",
    "count = 0\n",
    "pixel_count = 0\n",
    "h = int(PATCH_DIM/2)\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(h, image.shape[0] - h-1):\n",
    "    for j in range(h, image.shape[1] - h-1):\n",
    "        \n",
    "        if int(np.sum(mask[i-h:i+h+1,j-h:j+h+1])/PATCH_DIM**2) == 1:\n",
    "            pixel_count += 1\n",
    "            if count < BATCH_SIZE-1:\n",
    "                count += 1\n",
    "                feed[count] = image[i-h:i+h+1,j-h:j+h+1].reshape(-1)\n",
    "                rows[count] = i\n",
    "                cols[count] = j\n",
    "            else:\n",
    "                # Subtract training mean image\n",
    "                feed = feed - mean_np_img\n",
    "                \n",
    "                # Get predictions and draw accordingly on black image\n",
    "                \n",
    "                predictions = get_predictions(feed)\n",
    "                segmented[rows,cols] = predictions\n",
    "                \n",
    "                # Reset everything after passing feed to feedforward\n",
    "                rows = np.zeros(BATCH_SIZE, dtype='uint8')\n",
    "                cols = np.zeros(BATCH_SIZE, dtype='uint8')\n",
    "                feed = np.zeros((BATCH_SIZE, PATCH_DIM**2*3))\n",
    "                predictions = np.zeros(BATCH_SIZE)\n",
    "                count = 0\n",
    "                if pixel_count%3000 == 0:\n",
    "                    print \"%d / %d\"%(pixel_count, image.shape[0]*image.shape[1])\n",
    "                    current_time = time.time()\n",
    "                    print \"Time taken - > %f\" % (current_time - start_time)\n",
    "                    start_time = current_time\n",
    "\n",
    "segmented[0][0] = 0 # To nullify effects of final buffer\n",
    "                \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nbd(image, point):\n",
    "    \"\"\" Finds neighborhood around a point in an image\n",
    "        \n",
    "        Args: \n",
    "            image: Input image\n",
    "            point: A point around which we would like to find the neighborhood\n",
    "        \n",
    "        Output:\n",
    "            1d vector of size [PATCH_DIM*PATCH_DIM*3] which is a neighborhood\n",
    "            aroud the point passed in the parameters list\n",
    "    \"\"\"\n",
    "    i = point[0]\n",
    "    j = point[1]\n",
    "    h = int(PATCH_DIM/2)\n",
    "    return image[i-h:i+h+1,j-h:j+h+1].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUT_DIR = os.path.abspath(\"../Data/DRIVE/test_result\")\n",
    "\n",
    "# Make a directory to store the new images in\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.mkdir(OUT_DIR)\n",
    "    \n",
    "mean_np_img = np.asarray(mean_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding for all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = int(PATCH_DIM/2)\n",
    "# We want to access the data chunk by chunk such that each chunk has\n",
    "# approximately BATCH_SIZE pixels\n",
    "stride = int(np.sqrt(BATCH_SIZE))\n",
    "\n",
    "begin = time.time()\n",
    "start_time = time.time()\n",
    "with tf.Graph().as_default():\n",
    "    # Generate placeholders for the images and labels.\n",
    "    images_placeholder = placeholder_inputs(BATCH_SIZE)\n",
    "\n",
    "    # Build a Graph that computes predictions from the inference model.\n",
    "    logits = inference(images_placeholder, 1.0, 512)\n",
    "    sm = softmax(logits)\n",
    "\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Create a session for running Ops on the Graph.\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, '../Data/model.ckpt')\n",
    "        \n",
    "        # Once the model has been restored, we iterate through all images in the test set\n",
    "        for im_no in xrange(len(test)):\n",
    "            \n",
    "            print \"Working on image %d\" % (im_no+1)\n",
    "            image = io.imread(test[im_no])\n",
    "            mask = img_as_float(io.imread(mask_test[im_no]))\n",
    "            gt = img_as_float(io.imread(gt_test[im_no]))\n",
    "            \n",
    "            # We will start with a completely black image and update it chunk by chunk\n",
    "            segmented = np.zeros(image.shape[:2])\n",
    "\n",
    "            # We will use arrays to index the image and mask later\n",
    "            cols, rows = np.meshgrid(np.arange(image.shape[1]), np.arange(image.shape[0]))\n",
    "            row_col = np.stack([rows,cols], axis = 2)\n",
    "            # The neighborhood windows to be fed into the graph\n",
    "            feed = np.zeros((BATCH_SIZE, PATCH_DIM**2*3))\n",
    "            # The predicted classes for all the windows that were fed to the graph\n",
    "            predictions = np.zeros(BATCH_SIZE)\n",
    "\n",
    "            pixel_count = 0\n",
    "        \n",
    "            \n",
    "            i = h+1\n",
    "            while i < image.shape[0] - h-2:\n",
    "                j = h+1\n",
    "                while j < image.shape[1] - h-1:\n",
    "                    # A small check is made to ensure that not all pixels are black\n",
    "\n",
    "                    # Update i and j by adding stride but take care near the end\n",
    "                    i_next = min(i+stride, image.shape[0]-h-1)\n",
    "                    j_next = min(j+stride, image.shape[1]-h-1)\n",
    "                    \n",
    "                    if int(np.max(mask[i:i_next,j:j_next])) == 1:\n",
    "\n",
    "                        pixel_count += BATCH_SIZE # This will not be true for border cases though\n",
    "                                                  # but we don't care about the progress at the end\n",
    "\n",
    "                        \n",
    "\n",
    "\n",
    "                        # Once we get a chunk, we flatten it and map a function that returns \n",
    "                        # the neighborhood of each point\n",
    "\n",
    "                        #feed = np.array(map(lambda p: nbd(image, p), row_col[i:i_next, j:j_next].reshape(-1,2)))\n",
    "                        #print \" Feed shape = (%d, %d)\" % feed.shape\n",
    "                        chunk = np.array(map(lambda p: nbd(image, p), row_col[i:i_next, j:j_next].reshape(-1,2)))\n",
    "                        feed[:len(chunk)] = chunk\n",
    "                        \n",
    "                        # Subtract training mean image\n",
    "                        feed = feed - mean_np_img\n",
    "\n",
    "                        # Get predictions and draw accordingly on black image    \n",
    "                        predictions = sess.run([sm],\n",
    "                                       feed_dict={images_placeholder: feed})\n",
    "                        predictions = np.asarray(predictions).reshape(BATCH_SIZE, NUM_CLASSES)\n",
    "\n",
    "                        # Uncomment following line for non-probability plotting\n",
    "                        #predictions = np.argmax(predictions, axis=1)\n",
    "                        predictions = predictions[:,1]\n",
    "\n",
    "                        if not len(chunk) == BATCH_SIZE:\n",
    "                            predictions = predictions[:len(chunk)]\n",
    "                        segmented[rows[i:i_next, j:j_next], cols[i:i_next, j:j_next]] = predictions.reshape(i_next-i, j_next-j)\n",
    "\n",
    "                        # Reset everything after passing feed to feedforward\n",
    "                        feed = np.zeros((BATCH_SIZE, PATCH_DIM**2*3))\n",
    "                        predictions = np.zeros(BATCH_SIZE)\n",
    "\n",
    "                        if np.mod(pixel_count, 5000) < BATCH_SIZE:\n",
    "                            print \"%d / %d\"%(pixel_count, image.shape[0]*image.shape[1])\n",
    "                            current_time = time.time()\n",
    "                            print \"Time taken - > %f\" % (current_time - start_time)\n",
    "                            start_time = current_time\n",
    "                    j += stride\n",
    "                i += stride\n",
    "            segmented = np.multiply(segmented,mask)\n",
    "            segmented = segmented * (1.0/segmented.max())\n",
    "                \n",
    "            name = test[im_no].split('/')[-1].split('.')[0]\n",
    "            io.imsave(os.path.join(OUT_DIR, name+'.jpg'), segmented)\n",
    "print \"Total time = %f mins\" % ((time.time()-begin)/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
