<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Deep-vessel : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Deep-vessel</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/Ankush96/Deep-Vessel">View on GitHub</a>

          <h1 id="project_title">Deep-vessel</h1>
          <h2 id="project_tagline"></h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/Ankush96/Deep-Vessel/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/Ankush96/Deep-Vessel/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="ensemble-of-deep-convolutional-neural-networks-for-learning-to-detect-retinal-vessels-in-fundus-images" class="anchor" href="#ensemble-of-deep-convolutional-neural-networks-for-learning-to-detect-retinal-vessels-in-fundus-images" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Ensemble of Deep Convolutional Neural Networks for Learning to Detect Retinal Vessels in Fundus Images</h1>

<p>Vision impairment due to pathological damage of the retina can largely be prevented through periodic screening using fundus color imaging. However the challenge with large scale screening is the inability to exhaustively detect fine blood vessels crucial to disease diagnosis. This work presents a computational imaging framework using deep and ensemble learning for reliable detection of blood vessels in fundus color images. An ensemble of deep convolutional neural networks is trained to segment vessel and non-vessel areas of a color fundus image. During inference, the responses of the individual ConvNets of the ensemble are averaged to form the final segmentation. In experimental evaluation with the DRIVE database, we achieve the objective of vessel detection with maximum average accuracy of 91.8% (This accuracy is different from the accuracy reported in the paper because of different libraries used)</p>

<hr>

<table>
<thead>
<tr>
<th align="center">FUNDUS Image</th>
<th align="center">Manual Segmentation</th>
<th align="center">Predicted Segmentation</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/01_test_src.png?raw=True" width="220"></td>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/01_manual1.png?raw=True" width="220"></td>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/01_test.png?raw=True" width="220"></td>
</tr>
</tbody>
</table>

<hr>

<h2>
<a id="proposed-method" class="anchor" href="#proposed-method" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Proposed Method</h2>

<p><strong>Ensemble learning</strong> is a technique of using multiple models or experts for solving a particular artificial intelligence problem. Ensemble methods seek to promote diversity among the models they combine and reduce the problem related to overfitting of the training data. The outputs of the individual models of the ensemble are combined (e.g. by averaging) to form the final prediction.</p>

<p><strong>Convolutional neural networks</strong> (CNN or ConvNet) are a special category of artificial neural networks designed for processing data with a gridlike structure. The ConvNet architecture is based on sparse interactions and parameter sharing and is highly effective for efficient learning of spatial invariances in images. There are four kinds of layers in a typical ConvNet architecture: convolutional (conv), pooling (pool), fullyconnected (affine) and rectifying linear unit (ReLU). Each convolutional layer transforms one set of feature maps into another set of feature maps by convolution with a set of filters.</p>

<p>This paper makes an attempt to ameliorate the issue of subjectivity induced bias in feature representation by training an ensemble of 12 Convolutional Neural Networks (ConvNets) on raw color fundus images to discriminate vessel pixels from non-vessel ones. </p>

<p><strong>Dataset</strong>: The ensemble of ConvNets is evaluated by learning with the DRIVE training set (image id. 21-40) and
testing over the DRIVE test set (image id. 1-20). </p>

<p><strong>Learning mechanism</strong>: Each ConvNet is trained independently on a set of 120000 randomly chosen 3×31×31 patches.
Learning rate was kept constant across models at 5e − 4. Dropout probability and number of hidden units in
the penultimate affine layer of the different models were sampled respectively from U ([0:5; 0:9]) and U ({128; 256; 512}) where U(:) denotes uniform probability distribution over a given range. The models were trained using Adam algorithm with minibatch size 256. Some of these parameters are different from the paper. The user can set some of these parameters using command line arguments which is explained in later sections.</p>

<p><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Proposed-Method.png?raw=True" width="800"></p>

<hr>

<h2>
<a id="architecture" class="anchor" href="#architecture" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Architecture</h2>

<p>The ConvNets have the same organization of layers which can be described as: </p>

<p><strong>input- [conv - relu]-[conv - relu - pool] x 2 - affine - relu - [affine with dropout] - softmax</strong></p>

<p>(Schematic representation below)</p>

<p><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Architecture.png?raw=True" width="800"></p>

<hr>

<h2>
<a id="some-results" class="anchor" href="#some-results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Some Results</h2>

<table>
<thead>
<tr>
<th align="center">FUNDUS Image</th>
<th align="center">Magnified Section</th>
<th align="center">Ground Truth</th>
<th align="center">Prediction</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified1_1.png?raw=True" width="180"></td>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified1_2.png?raw=True" width="180"></td>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified1_3.png?raw=True" width="180"></td>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified1_4.png?raw=True" width="180"></td>
</tr>
<tr>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified2_1.png?raw=True" width="180"></td>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified2_2.png?raw=True" width="180"></td>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified2_3.png?raw=True" width="180"></td>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified2_4.png?raw=True" width="180"></td>
</tr>
<tr>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified3_1.png?raw=True" width="180"></td>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified3_2.png?raw=True" width="180"></td>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified3_3.png?raw=True" width="180"></td>
<td align="center"><img src="https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified3_4.png?raw=True" width="180"></td>
</tr>
</tbody>
</table>

<p>Note that the 3rd image is not easily visible to the human eye but our network does a good job of recognizing the fine structures.</p>

<hr>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Deep-vessel maintained by <a href="https://github.com/Ankush96">Ankush96</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
