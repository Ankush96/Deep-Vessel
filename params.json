{
  "name": "Deep-vessel",
  "tagline": "",
  "body": "\r\n# Ensemble of Deep Convolutional Neural Networks for Learning to Detect Retinal Vessels in Fundus Images\r\n\r\nVision impairment due to pathological damage of the retina can largely be prevented through periodic screening using fundus color imaging. However the challenge with large scale screening is the inability to exhaustively detect fine blood vessels crucial to disease diagnosis. This work presents a computational imaging framework using deep and ensemble learning for reliable detection of blood vessels in fundus color images. An ensemble of deep convolutional neural networks is trained to segment vessel and non-vessel areas of a color fundus image. During inference, the responses of the individual ConvNets of the ensemble are averaged to form the final segmentation. In experimental evaluation with the DRIVE database, we achieve the objective of vessel detection with maximum average accuracy of 91.8% (This accuracy is different from the accuracy reported in the paper because of different libraries used)\r\n<hr>\r\n\r\nFUNDUS Image             |  Manual Segmentation           | Predicted Segmentation\r\n:-------------------------:|:-------------------------:|:-------------------------:\r\n <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/01_test_src.png?raw=True\" width=\"220\"> |  <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/01_manual1.png?raw=True\" width=\"220\"> | <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/01_test.png?raw=True\" width=\"220\">\r\n\r\n<hr>\r\n## Proposed Method\r\n\r\n**Ensemble learning** is a technique of using multiple models or experts for solving a particular artificial intelligence problem. Ensemble methods seek to promote diversity among the models they combine and reduce the problem related to overfitting of the training data. The outputs of the individual models of the ensemble are combined (e.g. by averaging) to form the final prediction.\r\n\r\n**Convolutional neural networks** (CNN or ConvNet) are a special category of artificial neural networks designed for processing data with a gridlike structure. The ConvNet architecture is based on sparse interactions and parameter sharing and is highly effective for efficient learning of spatial invariances in images. There are four kinds of layers in a typical ConvNet architecture: convolutional (conv), pooling (pool), fullyconnected (affine) and rectifying linear unit (ReLU). Each convolutional layer transforms one set of feature maps into another set of feature maps by convolution with a set of filters.\r\n\r\nThis paper makes an attempt to ameliorate the issue of subjectivity induced bias in feature representation by training an ensemble of 12 Convolutional Neural Networks (ConvNets) on raw color fundus images to discriminate vessel pixels from non-vessel ones. \r\n\r\n**Dataset**: The ensemble of ConvNets is evaluated by learning with the DRIVE training set (image id. 21-40) and\r\ntesting over the DRIVE test set (image id. 1-20). \r\n\r\n**Learning mechanism**: Each ConvNet is trained independently on a set of 120000 randomly chosen 3×31×31 patches.\r\nLearning rate was kept constant across models at 5e − 4. Dropout probability and number of hidden units in\r\nthe penultimate affine layer of the different models were sampled respectively from U ([0:5; 0:9]) and U ({128; 256; 512}) where U(:) denotes uniform probability distribution over a given range. The models were trained using Adam algorithm with minibatch size 256. Some of these parameters are different from the paper. The user can set some of these parameters using command line arguments which is explained in later sections.\r\n\r\n<img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Proposed-Method.png?raw=True\" width=\"800\">\r\n\r\n<hr>\r\n\r\n## Architecture\r\n\r\nThe ConvNets have the same organization of layers which can be described as: \r\n\r\n**input- [conv - relu]-[conv - relu - pool] x 2 - affine - relu - [affine with dropout] - softmax**\r\n\r\n(Schematic representation below)\r\n\r\n<img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Architecture.png?raw=True\" width=\"800\">\r\n\r\n<hr>\r\n## Some Results\r\n\r\nFUNDUS Image             |  Magnified Section          | Ground Truth          | Prediction\r\n:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:\r\n <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified1_1.png?raw=True\" width=\"180\"> | <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified1_2.png?raw=True\" width=\"180\"> | <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified1_3.png?raw=True\" width=\"180\"> | <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified1_4.png?raw=True\" width=\"180\"> \r\n <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified2_1.png?raw=True\" width=\"180\"> | <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified2_2.png?raw=True\" width=\"180\"> | <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified2_3.png?raw=True\" width=\"180\"> | <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified2_4.png?raw=True\" width=\"180\"> \r\n <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified3_1.png?raw=True\" width=\"180\"> | <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified3_2.png?raw=True\" width=\"180\"> | <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified3_3.png?raw=True\" width=\"180\"> | <img src=\"https://github.com/Ankush96/Deep-Vessel/blob/master/images/Magnified3_4.png?raw=True\" width=\"180\"> \r\n \r\n Note that the 3rd image is not easily visible to the human eye but our network does a good job of recognizing the fine structures.\r\n \r\n<hr>",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}